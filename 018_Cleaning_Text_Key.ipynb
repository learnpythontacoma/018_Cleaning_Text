{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='graphics/text_cleaning.png'>\n",
    "\n",
    "<img src='graphics/spacer.png'>\n",
    "\n",
    "<center><font style=\"font-size:40px;\">Cleaning Text from Web Scraping Indeed </font></center>\n",
    "<center>Prepared and coded by Ben P. Meredith, Ed.D.</center>\n",
    "\n",
    "\n",
    "When we were last together, we began developing a program to web scrape job announcements from Indeed. In our program, we saved vital information from the job announcements to a Pandas DataFrame. \n",
    "\n",
    "We were also left with a few tasks to code prior to today's discussion. As you may recall, I tasked you to do the following:\n",
    "\n",
    ">1. Find and remove duplicate job announcements\n",
    ">1. Identify if a table already exists for a search term\n",
    "    - if it does exist, add new entries to the bottom of the table\n",
    "    - find and remove duplicate job announcements\n",
    "\n",
    "If you took the opportunity to work on the code for this program, you realized that the second task (Identify if a table already exists for a search term) required you to do a bit of investigation on your own. I hope that you took advantage of this opportunity and went out to StackOverFlow.com for your research. This task was not one that we covered prior to your challenge, but we will cover it in this notebook. \n",
    "\n",
    "There was a third task that we needed to do in order to make our data more valuable. If you took the opportunity to look at the data as it was pulled from Indeed, you will have noticed that it is far from clean. In fact, it is downright dirty with HTML marks and code. Later in this notebook, we will work together on cleaning that data so it is easier for us to process and thus analyze later. This work will be our introduction to the data science sub-field called **Natural Language Processing**, which we will discuss below. But first, let's go over the assigned tasks and look at solutions. \n",
    "\n",
    "# Loading Fresh Libraries and Data\n",
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:26:29.568711Z",
     "start_time": "2020-06-14T15:26:28.636545Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import our needed libraries\n",
    "\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our Pull Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:26:30.504744Z",
     "start_time": "2020-06-14T15:26:30.497611Z"
    }
   },
   "outputs": [],
   "source": [
    "def job_data_pull(url):\n",
    "    page = requests.get(url)# go to the page noted by the url\n",
    "    page_contents = BeautifulSoup(page.content, 'lxml')#extract the contents of the page\n",
    "    \n",
    "    #only getting the tags for organic job postings and not the ones that are sponsored\n",
    "    tags = page_contents.find_all('div', {'data-tn-component' : \"organicJob\"})\n",
    "    \n",
    "    #getting the list of companies that have the organic job posting tags\n",
    "    companies = [x.span.text for x in tags]\n",
    "    \n",
    "    #extracting the features like the company name, complete link, date, etc.\n",
    "    attributes = [x.h2.a.attrs for x in tags]\n",
    "    dates = [x.find_all('span', {'class':'date'}) for x in tags]\n",
    "    \n",
    "    # update attributes dictionaries with company name and date posted\n",
    "    [attributes[i].update({'company': companies[i].strip()}) for i, x in enumerate(attributes)]\n",
    "    [attributes[i].update({'date posted': dates[i][0].text.strip()}) for i, x in enumerate(attributes)]\n",
    "    return attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify if a Data Table with our Scrapes Already Exists using a Function\n",
    "\n",
    "Part of the utility of our web scraper for Indeed is to build a single DataFrame for each job that we are seeking. Currently, our program is set up to establish a new DataFrame every time it goes out to scrap. It should take no imagination to understand that if we do this, we will either overwrite any previously pulled data or we will be left with multiple tables of jobs with the same titles. So, let's write some functions to do the following.\n",
    "\n",
    "1. Identify if we have an existing DataFrame table for the job title we are seeking.\n",
    "1. IF we do not have an existing DataFrame for that job title, THEN establish one for that job title.\n",
    "1. Or IF we do have a a DataFrame that already exists for the job title we are seeking, THEN load that DataFrame and populate it with the new information that we scrape. \n",
    "\n",
    "To do this, we are going to need to use the `Path` library, which is a Python library that allows you to navigate through your computer directories and either find or match existing files. That is what the `find_file(pathway)` function in the next block does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:26:31.878267Z",
     "start_time": "2020-06-14T15:26:31.874914Z"
    }
   },
   "outputs": [],
   "source": [
    "# Determine if a file exists within a pathway\n",
    "def find_file(pathway):#pathway is the path to the file\n",
    "    from pathlib import Path\n",
    "    pathway = Path(pathway)# convert the pathway to an actual path from a string\n",
    "    if pathway.exists():#Determine if the file exists\n",
    "        return 1 #1 = file exists\n",
    "    else: \n",
    "        return 0 # 0 = file does not exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second function we will need will be one to determine IF a DataFrame for the job title we are searching already exists. The `initialize_data_log(job_title)` function in the next block does that. \n",
    "\n",
    "This next function will take the job title that you input at the start of the program, then it will (using the conventions we established in titling our DataFrames) look for a DataFrame with that job search title in it. IF the DataFrame exists, THEN it will load it and we can begin working from where we last left off. \n",
    "\n",
    "However, IF there isn't a DataFrame for our searched job title, THEN it will load a new DataFrame under the new job title that we are seeking. \n",
    "\n",
    "We are establishing both of these functions now, but we will not call them until AFTER the user has inputted the job title they are seeking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:26:33.110612Z",
     "start_time": "2020-06-14T15:26:33.104903Z"
    }
   },
   "outputs": [],
   "source": [
    "#Initialize the data_log by discovering if it exists. If it does, load it. Otherwise, form one. \n",
    "def initialize_data_log(job_title):\n",
    "    import pandas as pd\n",
    "    job_title = job_title.replace(' ', '_')\n",
    "    data_file = ('data/'+job_title+'_job_search.csv')\n",
    "    answer = find_file(data_file)\n",
    "    if answer == 1:\n",
    "        df = pd.read_csv(data_file, index_col=0)\n",
    "        df = df.drop(['level_0'], axis=1, errors='ignore')#Drops level_0 column that keeps showing up \n",
    "    else:\n",
    "        df = pd.DataFrame(columns=('job_id', 'title', 'company', 'url', 'text', 'pull_date'))\n",
    "        df.to_csv(data_file)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Basic Scraping Program so We Can Grab Some Data for this Notebook Work\n",
    "\n",
    "This next block is a copy of our basic scraping program that we developed previously. We brought it forward to this notebook \n",
    "1. for ease of having everything we need in one notebook\n",
    "1. to incorporate our two new functions\n",
    "\n",
    "In Line 8, you will see that we are using the `initialize_data_log(job_title)` function. Embedded in that function is the `find_file(pathway)` function. Notice that this function come AFTER the job title input. We do this because we need the user to tell Python what job title they are wanting to search for. And from that input Python will search for a DataFrame for that job title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:32.025986Z",
     "start_time": "2020-06-14T15:26:34.554633Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For what job title are you interested in searching? data scientist\n",
      "What is your zip code?98101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:00, 564.71it/s]\n",
      "116it [00:45,  2.55it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>pull_date</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>token_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jl_ef4f45eee0d53000</td>\n",
       "      <td>Engineering Manager, Ads Machine Learning</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=ef4f45eee0d5...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>About Pinterest:Millions of people across the ...</td>\n",
       "      <td>['About', 'Pinterest', ':', 'Millions', 'of', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jl_b0fe1a91ffb0e24d</td>\n",
       "      <td>Applied Scientist</td>\n",
       "      <td>Amazon.com Services LLC</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=b0fe1a91ffb0...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>- MS or PhD degree in computer science, opera...</td>\n",
       "      <td>['-', 'MS', 'or', 'PhD', 'degree', 'in', 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jl_900d5e7e57d3225e</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amazon.com Services LLC</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=900d5e7e57d3...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>- PhD or equivalent Master's Degree plus 4+ y...</td>\n",
       "      <td>['-', 'PhD', 'or', 'equivalent', 'Master', \"'s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jl_a0de3ccca1e027a6</td>\n",
       "      <td>Sr Director of Data and Analytics</td>\n",
       "      <td>Equiscript</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=a0de3ccca1e0...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>At Equiscript, we improve access to healthcare...</td>\n",
       "      <td>['At', 'Equiscript', ',', 'we', 'improve', 'ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jl_5d0204fe56e8daee</td>\n",
       "      <td>ES Tech, Machine Learning Engineer</td>\n",
       "      <td>Amazon.com Services LLC</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=5d0204fe56e8...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>- Programming experience with at least one mo...</td>\n",
       "      <td>['-', 'Programming', 'experience', 'with', 'at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>jl_fa1fe3575ef75d4b</td>\n",
       "      <td>C++ Software Engineer - Autonomous Vehicle A.I...</td>\n",
       "      <td>TuSimple</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=fa1fe3575ef7...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>jl_9522ae307d31afc4</td>\n",
       "      <td>AI/ML - Software Engineer, Siri Authoring Tools</td>\n",
       "      <td>Apple</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=9522ae307d31...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>jl_12e31b3b1c1a3668</td>\n",
       "      <td>Senior AI Engineer</td>\n",
       "      <td>Harebrained Schemes</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=12e31b3b1c1a...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>jl_37768e3c300e0ad2</td>\n",
       "      <td>Principal Statistician</td>\n",
       "      <td>Seattle Genetics, Inc.</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=37768e3c300e...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>jl_c598121ff7201e59</td>\n",
       "      <td>Data &amp; AI Specialist</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=c598121ff720...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  job_id                                              title  \\\n",
       "0    jl_ef4f45eee0d53000          Engineering Manager, Ads Machine Learning   \n",
       "1    jl_b0fe1a91ffb0e24d                                  Applied Scientist   \n",
       "2    jl_900d5e7e57d3225e                                     Data Scientist   \n",
       "3    jl_a0de3ccca1e027a6                  Sr Director of Data and Analytics   \n",
       "4    jl_5d0204fe56e8daee                 ES Tech, Machine Learning Engineer   \n",
       "..                   ...                                                ...   \n",
       "111  jl_fa1fe3575ef75d4b  C++ Software Engineer - Autonomous Vehicle A.I...   \n",
       "112  jl_9522ae307d31afc4    AI/ML - Software Engineer, Siri Authoring Tools   \n",
       "113  jl_12e31b3b1c1a3668                                 Senior AI Engineer   \n",
       "114  jl_37768e3c300e0ad2                             Principal Statistician   \n",
       "115  jl_c598121ff7201e59                               Data & AI Specialist   \n",
       "\n",
       "                     company  \\\n",
       "0                  Pinterest   \n",
       "1    Amazon.com Services LLC   \n",
       "2    Amazon.com Services LLC   \n",
       "3                 Equiscript   \n",
       "4    Amazon.com Services LLC   \n",
       "..                       ...   \n",
       "111                 TuSimple   \n",
       "112                    Apple   \n",
       "113      Harebrained Schemes   \n",
       "114   Seattle Genetics, Inc.   \n",
       "115                Microsoft   \n",
       "\n",
       "                                                   url  \\\n",
       "0    https://www.indeed.com/viewjob?jk=ef4f45eee0d5...   \n",
       "1    https://www.indeed.com/viewjob?jk=b0fe1a91ffb0...   \n",
       "2    https://www.indeed.com/viewjob?jk=900d5e7e57d3...   \n",
       "3    https://www.indeed.com/viewjob?jk=a0de3ccca1e0...   \n",
       "4    https://www.indeed.com/viewjob?jk=5d0204fe56e8...   \n",
       "..                                                 ...   \n",
       "111  https://www.indeed.com/viewjob?jk=fa1fe3575ef7...   \n",
       "112  https://www.indeed.com/viewjob?jk=9522ae307d31...   \n",
       "113  https://www.indeed.com/viewjob?jk=12e31b3b1c1a...   \n",
       "114  https://www.indeed.com/viewjob?jk=37768e3c300e...   \n",
       "115  https://www.indeed.com/viewjob?jk=c598121ff720...   \n",
       "\n",
       "                                                  text   pull_date  \\\n",
       "0    <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-05-25   \n",
       "1    <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-05-25   \n",
       "2    <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-05-25   \n",
       "3    <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-05-25   \n",
       "4    <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-05-25   \n",
       "..                                                 ...         ...   \n",
       "111  <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-06-14   \n",
       "112  <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-06-14   \n",
       "113  <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-06-14   \n",
       "114  <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-06-14   \n",
       "115  <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-06-14   \n",
       "\n",
       "                                            clean_text  \\\n",
       "0    About Pinterest:Millions of people across the ...   \n",
       "1     - MS or PhD degree in computer science, opera...   \n",
       "2     - PhD or equivalent Master's Degree plus 4+ y...   \n",
       "3    At Equiscript, we improve access to healthcare...   \n",
       "4     - Programming experience with at least one mo...   \n",
       "..                                                 ...   \n",
       "111                                                NaN   \n",
       "112                                                NaN   \n",
       "113                                                NaN   \n",
       "114                                                NaN   \n",
       "115                                                NaN   \n",
       "\n",
       "                                            token_text  \n",
       "0    ['About', 'Pinterest', ':', 'Millions', 'of', ...  \n",
       "1    ['-', 'MS', 'or', 'PhD', 'degree', 'in', 'comp...  \n",
       "2    ['-', 'PhD', 'or', 'equivalent', 'Master', \"'s...  \n",
       "3    ['At', 'Equiscript', ',', 'we', 'improve', 'ac...  \n",
       "4    ['-', 'Programming', 'experience', 'with', 'at...  \n",
       "..                                                 ...  \n",
       "111                                                NaN  \n",
       "112                                                NaN  \n",
       "113                                                NaN  \n",
       "114                                                NaN  \n",
       "115                                                NaN  \n",
       "\n",
       "[116 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ask the user what job description they are interested in searching for and where\n",
    "job_title = input('For what job title are you interested in searching? ')\n",
    "location = input('What is your zip code?' )\n",
    "\n",
    "#establish a DF to store the data if one does not exist\n",
    "#if a search term data already exists, use it.\n",
    "\n",
    "df = initialize_data_log(job_title)\n",
    "\n",
    "\n",
    "#Establishes the variables we will need for the Indeed Search URL\n",
    "getVars = {'q' : job_title, 'l' : location, 'fromage' : 'last', 'sort' : 'date'}\n",
    "\n",
    "#Assembles the Indeed Search URL from the attributes above\n",
    "url = ('https://www.indeed.com/jobs?' + urllib.parse.urlencode(getVars))\n",
    "\n",
    "#Using our uniquely assembled URL, we run the subroutine to get the job data from the function we defined above.\n",
    "answer = job_data_pull(url)\n",
    "\n",
    "starting_length = len(df)\n",
    "\n",
    "# Using the data gathered by our function, we are assigning information to our DataFrame AND we are \n",
    "# getting the information we need to retrieve the job description text. \n",
    "for index, a in tqdm(enumerate(answer)):\n",
    "    df.loc[starting_length + index, 'url'] = a['id'].replace('jl_', 'https://www.indeed.com/viewjob?jk=')\n",
    "    df.loc[starting_length + index, 'title'] = a['title']\n",
    "    df.loc[starting_length + index, 'company'] = a['company']\n",
    "    df.loc[starting_length + index, 'job_id'] = a['id']\n",
    "    df.loc[starting_length + index, 'pull_date'] = datetime.date(datetime.now())\n",
    "\n",
    "# Using the URLs we generated in line 20, we use them in this FOR loop to retrieve the job description text. \n",
    "for index, url in tqdm(enumerate(df.url)):\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        content = BeautifulSoup(page.content, \"html.parser\")\n",
    "        job_text = content.find('div', class_=\"jobsearch-jobDescriptionText\")\n",
    "        df.loc[index, 'text'] = str(job_text)\n",
    "    except KeyError:\n",
    "        df.loc[index, 'text'] = str(job_text)\n",
    "\n",
    "job_title = job_title.replace(' ', '_')\n",
    "df.to_csv('data/'+job_title+'_job_search.csv')\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:37.610143Z",
     "start_time": "2020-06-14T15:27:37.605715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The .replace( ) Command\n",
    "\n",
    "When it comes to cleaning text, the most basic and most often used command is the `.replace()` command. As you can safely assume, the `.replace()` command replaces text or special characters (user defined) with a user defined word, letters, or special character. \n",
    "\n",
    "The syntax of the `.replace()` command is simple:\n",
    "\n",
    "> text = text.replace('what you want to replace', 'what you want it replaced with')\n",
    "\n",
    "Let's look at the following example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:39.736503Z",
     "start_time": "2020-06-14T15:27:39.733699Z"
    }
   },
   "outputs": [],
   "source": [
    "# Our test string\n",
    "\n",
    "test_text = 'The jolly merchant of Verona'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our `test_text`, we want to replace the word 'jolly' with the word 'happy'. Below is how we do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:40.998631Z",
     "start_time": "2020-06-14T15:27:40.995354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The happy merchant of Verona\n"
     ]
    }
   ],
   "source": [
    "test_text = test_text.replace('jolly', 'happy')\n",
    "\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our first example, we replaced an entire word. In the next example, we want to replace the punctuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:42.497917Z",
     "start_time": "2020-06-14T15:27:42.495278Z"
    }
   },
   "outputs": [],
   "source": [
    "test_text = 'You are kidding.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:42.918789Z",
     "start_time": "2020-06-14T15:27:42.915930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are kidding!\n"
     ]
    }
   ],
   "source": [
    "test_text = test_text.replace('.', '!')\n",
    "\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Using the .replace( ) to clean text\n",
    "\n",
    "Now that we have covered the `.replace()` command, you can use it to develop a text cleaning function. \n",
    "\n",
    ">1. In the next block, pull the text from several rows in your DataFrame to examine them\n",
    ">1. Develop a text cleaning function using the `.replace()` command\n",
    ">1. When you have a function that works for you, run every entry in the ['text'] column in the DataFrame through the function and save the results in a new column titled 'clean_text'.\n",
    ">1. Finally, print out a sample of 5 entries from the 'clean_text' column alone to make sure your function is working. \n",
    "\n",
    "<font color='red'>**HINT**:</font> Think carefully about what you pull and what you replace text with. If you consider it carefully rather than jumping right into the task, you can make your text human readable and human pretty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:44.570853Z",
     "start_time": "2020-06-14T15:27:44.564790Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"jobsearch-jobDescriptionText\" id=\"jobDescriptionText\"><div><p><b>About Pinterest:</b></p>\n",
      "<p>\n",
      "Millions of people across the world come to Pinterest to find new ideas every day. It’s where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. As a Pinterest employee, you’ll be challenged to take on work that upholds this mission and pushes Pinterest forward. You’ll grow as a person and a leader in your field, all the while helping users make their lives better in the positive corner of the internet.</p>\n",
      "<p>\n",
      "Before scaling their spend, advertisers want to know that Pinterest is performing for them. Come lead the team that interfaces with advertisers, collecting their sales data and matching it to our internal user databases, and build models and systems to connect the dots between the aspirations of pinners and the products offered by our partners.</p>\n",
      "<p><b>\n",
      "What you’ll do</b></p>\n",
      "<ul>\n",
      "<li>Build and improve the machine learning models for ads measurement.</li>\n",
      "<li>Develop models for user matching and conversion attributions.</li>\n",
      "<li>Develop new techniques to mine the offsite signals to drive ads performance, e.g., retargeting.</li>\n",
      "<li>Work on large scale data systems, backend services, and product integration</li>\n",
      "</ul>\n",
      "<p><b>What we’re looking for:</b></p>\n",
      "<ul>\n",
      "<li>MS or Ph.D degree in Computer Science, Statistics, or related field</li>\n",
      "<li>6+ years of relevant experience</li>\n",
      "<li>Strong industry experience in machine learning</li>\n",
      "<li>Cross-functional collaborator and strong communicator</li>\n",
      "<li>Preferred, but not required, background in computational advertising</li>\n",
      "</ul>\n",
      "<p>#LI-JY1</p></div></div> \n",
      "\n",
      "************************************************************************\n",
      "<div class=\"jobsearch-jobDescriptionText\" id=\"jobDescriptionText\"><ul><li>MS or PhD degree in computer science, operations research, statistics, engineering, or mathematics</li><li>5+ years of experience in the field with a proven track record</li><li>Experience with fast prototyping</li><li>Experience with data mining or machine learning applications</li><li>Experience working effectively with software engineering teams</li><li>Excellent written and verbal communication skills</li></ul>\n",
      "<br/>\n",
      "<p>Amazon AI is looking for world class scientists to join its AI Lab. This group is entrusted with developing core machine learning algorithms for AWS. As a part of the AI Lab you will invent, implement, and deploy state of the art machine learning algorithms and systems. You will build prototypes and explore novel solutions to new problems at scale. You will interact closely with our customers and with the academic community. You will be at the heart of a growing and exciting focus area for AWS and work with other acclaimed engineers and world famous scientists.</p>\n",
      "<br/>\n",
      "As a Scientist in the AI Lab are expected be an expert in an area relevant for large scale machine learning and its applications. Our particular focuses include temporal models particularly for forecasting, recommendation systems and reinforcement learning. Experience with deploying ML in practice is a plus.\n",
      "Your position will require you to:\n",
      "· Be an active member of a software development team.\n",
      "· Improve and accelerate our technology with science, statistical modeling, algorithm design, and prototyping.\n",
      "· Maintain an understanding of industry and technology trends in said area of research.\n",
      "· Contribute to Amazon's Intellectual Property through patents and/or external publications.\n",
      "· Understand business context to decisions made within and across groups.\n",
      "· Effectively communicate with senior management, colleagues, the open source community, and academia.\n",
      "· Recognize and help hire top talent in your field.\n",
      "· Mentor others in achieving their career growth potential.\n",
      "· Drive an independent research agenda that is well-aligned with business needs.\n",
      "Amazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.</div> \n",
      "\n",
      "************************************************************************\n",
      "<div class=\"jobsearch-jobDescriptionText\" id=\"jobDescriptionText\"><ul><li>PhD or equivalent Master's Degree plus 4+ years of experience in a quantitative field.</li><li>Strong analytical skills.</li><li>2+ years of experience of building predictive models for business and proficiency in model development and model validation.</li><li>Experience in efficiently handling large data sets, e.g., by using SQL, and databases in a business environment.</li><li>Experience with R, Python, Matlab or other scripting languages.</li></ul>\n",
      "<br/>\n",
      "<div>The Amazon Devices-Demand Planning team is seeking an outstanding scientist with strong analytical and communication skills to help with demand forecasting and supply optimization for the entire Amazon device family of products and accessories. We develop scalable and robust state-of-the-art solutions that involve learning from different data sources. This role is central to the continued growth of Amazon Device division as we have grown from the first Kindle E-Reader to a vast portfolio of Echo, Fire TV, Fire Tablet, E-Reader, Ring and many other devices. With better forecasts we drive down supply chain costs, enabling the offer of lower prices and better in-stock selection for our customers.<br/>\n",
      "In this role, you will have an opportunity to both develop advanced scientific solutions and drive critical customer and business impacts. You will play a key role to drive end-to-end solutions from understanding our business requirements, exploring a large amount of historical data, building prototypes and exploring conceptually new solutions, to working with partner teams for prod deployment. You will collaborate closely with engineering peers as well as business stakeholders. You will be at the heart of a growing and exciting focus area for Amazon Devices.<br/>\n",
      "<br/>\n",
      "You are an individual with outstanding analytical abilities, excellent communication skills, and are comfortable working with cross-functional teams and systems. You will be responsible for researching, prototyping, experimenting, and analyzing predictive models.<br/>\n",
      "<br/>\n",
      "Key responsibilities:<br/>\n",
      "<ul><li>Research and develop new methodologies for demand forecasting and price modeling.</li><li>Improve upon existing methodologies by adding new data sources and implementing model enhancements.</li><li>Drive scalable solutions.</li><li>Create and track accuracy and performance metrics (both technical and business metrics).</li><li>Create, enhance, and maintain technical documentation, and present to other scientists, engineers and business leaders.</li><li>Drive best practices on the team; mentor and guide junior members to achieve their career growth potential.</li></ul></div>\n",
      "<br/>\n",
      "<div><ul><li>Experience with time series modeling and machine learning forecasting.</li><li>Experience with price modeling.</li></ul></div></div> \n",
      "\n",
      "************************************************************************\n",
      "<div class=\"jobsearch-jobDescriptionText\" id=\"jobDescriptionText\"><div>At Equiscript, we improve access to healthcare in the communities we serve. We are able to do this through the motivation, ingenuity, and dedication of our talented team.<br/>\n",
      "<br/>\n",
      "Are you looking for a career where you can be part of a successful, growing business that is doing meaningful work in communities across the country?<br/>\n",
      "<br/>\n",
      "Located in historic North Charleston and Salt Lake City, Equiscript has been on the Inc. 5000 list of Fastest Growing Companies in the United States for the past four years and was chosen as one of the Best Places to Work in South Carolina three years in a row. We were also named one of Modern Healthcare's 2019 Best Places to Work in Healthcare and received the UT Healthy Worksite Award for 2020. We are a dynamic, growing company that values its employees and the patients and health centers we serve. As passionate people who enjoy coming to work and being part of a team, we are looking for candidates who will support and embrace our company’s Cause and Core Values. If this is you, apply today!\n",
      "<div><br/>\n",
      "<b>Sr Director of Data &amp; Analytics:</b><b>:</b>\n",
      "<p><b>\n",
      "General Description:</b></p>\n",
      "<p>Equiscript is seeking an experienced candidate to serve in the role of Senior Director of Data and Analytics (SDDA). The SDDA will serve as a department and business leader, reporting to the CFO.</p>\n",
      "<p><b>High-Level Vision - :</b>the SDDR is responsible for the big picture of the data priorities and strategy for the company. A high level of understanding of both data and strategy and the company’s business is required.</p>\n",
      "<p><b>Implementation -:</b> The SDDR is responsible for the implementation of data-driven solutions within the company’s strategy at every level in the company. This requires the ability to manage teams on technical projects and build a business case around technical projects with many variables and uncertainty.</p>\n",
      "<p><b>Data Accuracy, Security, and Privacy - :</b>the SDDR is responsible for collecting and maintaining accurate data, ensuring data security, and devising and implementing data privacy policies. The SDDR is to work with leadership to develop, define, and implement legal and ethical guidelines for the collection and use of data.</p>\n",
      "<p><b>Identifying Business Opportunities - :</b>The SDDR is the person most responsible for identifying business opportunities discovered through data. In broad terms, the SDDR should increase revenue or decrease costs based upon information learned through data initiatives.</p>\n",
      "<p><b>Data-Driven Culture Leader - :</b>The SDDR must serve as the leader for a data-driven culture within the company. This includes communicating to everyone at the company the importance of data, security, and privacy as well as the business value of data.</p><br/>\n",
      "<p><b>Key Responsibilities:</b></p>\n",
      "<p>The SDDA will develop new ways to interpret and use data to advance Equiscript’s business. Working closely with the Sr. Director of Information Services, this position will build the structure and processes necessary to serve internal business users. In this role, the SDDA will define how Equiscript looks at reporting, tracking, and decision-making. The SDDA will:</p>\n",
      "<div><ul><li></li></ul><p>Have expertise in creating and driving business value and growth through the effective use of data.</p>\n",
      "<ul><li></li></ul><p>Collaborate with IT on the architecture, design, integration, and staging of data and the development, implementation, and maintenance of the associated data storage systems.</p>\n",
      "<ul><li></li></ul><p>Be responsible for developing and administering Equiscript’s data and information strategy in order to facilitate and enhance organizational decision-making and data utilization across the company.</p>\n",
      "<ul><li></li></ul><p>Lead a centralized Data and Analytics service and develop data-related policies and procedures; design, improve, and streamline organizational data systems; and drive innovation in the area of enterprise-wide data science, analysis, and visualization.</p>\n",
      "<ul><li></li></ul><p>Be responsible for recruiting staff or engaging contractors that can use emerging technologies to improve the performance of the company.</p>\n",
      "<ul><li></li></ul><p>Be responsible for developing and administering Equiscript’s data and information strategy in order to facilitate and enhance organizational decision-making and data utilization across the company.</p>\n",
      "<ul><li></li></ul><p>Be responsible for overseeing the development and management of new machine learning and predictive modeling algorithms.</p>\n",
      "<ul><li></li></ul><p>Be responsible for communicating effectively with all company departments and helping those departments perform to a higher standard with tools developed under the oversight of the SDDA.</p>\n",
      "<ul><li></li></ul><p>Serve as a system-wide leader for data and analytics. Working closely with our client, patient, and pharmacy facing teams, develop a comprehensive understanding of the company’s overall business goals and data analytics needs</p>\n",
      "<ul><li></li></ul><p>Analyze data, identify trends, and recommend how to improve and grow the business</p>\n",
      "<ul><li></li></ul><p>Build and establish the automation of reports &amp; dashboards – identify and select analytics partners to improve reporting</p>\n",
      "<ul><li></li></ul><p>Own and expand patient identification and patient lifecycle and lifetime value reporting</p>\n",
      "<ul><li></li></ul><p>Present data in a clear and concise way to the executive team</p>\n",
      "<ul><li></li></ul><p>Research the latest technologies and assess their impact on business trends</p><br/>\n",
      "</div><p><b>Professional Qualities:</b></p>\n",
      "<div><ul><li></li></ul><p>Evidence of strong leadership and communication skills at a C- or board level</p>\n",
      "<ul><li></li></ul><p>Experience in information management projects and programs</p>\n",
      "<ul><li></li></ul><p>Familiarity with big data solutions</p>\n",
      "<ul><li></li></ul><p>Familiarity with data governance and quality control</p>\n",
      "<ul><li></li></ul><p>Background in statistics or mathematics</p>\n",
      "<ul><li></li></ul><p>Experience with creating best practices and methodologies for technical projects</p>\n",
      "<ul><li></li></ul><p>Experience managing technical teams</p>\n",
      "<ul><li></li></ul><p>Understanding of and experience building business cases for large technical projects</p>\n",
      "<ul><li></li></ul><p>Familiarity with data modelling and visualization techniques</p>\n",
      "<ul><li></li></ul><p>Strong business experience in the field</p><br/>\n",
      "</div><p><b>Preferred Experience:</b></p>\n",
      "<div><ul><li></li></ul><p>Bachelor’s or graduate degree in a quantitative field such as Mathematics, Statistics, Computer Science, Finance, Economics, or a related field.</p>\n",
      "<ul><li></li></ul><p>5-8 years of experience working with data analytics teams to provide reporting, analysis, modeling, and strategic insight</p>\n",
      "<ul><li></li></ul><p>Experience with a variety of analytics platforms and database programming languages (i.e. CRM, Web Analytics, BI tools, etc)</p>\n",
      "<ul><li></li></ul><p>Experience in integrating complex, inter-departmental processes and information strategies, and/or designing strategic metrics and scorecards required.</p>\n",
      "<ul><li></li></ul><p>Experience running data analytics teams using the latest data mining, machine learning and/or artificial intelligence techniques required. Clinical background, or technical background in the healthcare domain is highly desirable.</p>\n",
      "<ul><li></li></ul><p>Hands-on experience with implementing data management programs preferred.</p>\n",
      "<ul><li></li></ul><p>Ability to provide written and oral interpretation of highly specialized terms and data, and the ability to present this data to others with different levels of expertise</p><br/>\n",
      "</div><p><br/>\n",
      "<b>Computer Skills:</b><br/>\n",
      "</p><div><ul><li>Statistical analysis software/packages such as R, Minitab, SAS/STAT, etc.</li></ul>\n",
      "<ul><li></li></ul><p>Visualization/BI tools such as Tableau, PowerBI, etc.</p>\n",
      "<ul><li></li></ul><p>Ability to write and tune SQL queries</p>\n",
      "<ul><li></li></ul><p>Advanced Database/warehouse/lake knowledge; Master Data Management (MDM) applications; and Extract-Transform-Load (ETL/ELT) tool</p><br/>\n",
      "</div><p><b>Physical Requirements:</b></p>\n",
      "<div><ul><li></li></ul><p>Requires the ability to sit or stand for long periods of time, occasional stooping, and reaching; May require lifting up to 25 pounds; requires a normal range of vision and hearing with or without accommodations.</p><br/>\n",
      "</div><p><b>Additional Information:</b></p>\n",
      "<div><ul><li></li></ul><p>Cleared Background Check Required</p><br/>\n",
      "</div><p><b>Employment Information:</b></p>\n",
      "<div><ul><li></li></ul><p>Position located in North Charleston, SC but remote candidates will be considered. Remote candidates will be expected to travel approximately 20% to the main office.</p>\n",
      "<ul><li></li></ul><p>Benefits include health plan, dental, vision, paid time off</p>\n",
      "<ul><li></li></ul><p>Flex time</p>\n",
      "</div><div><ul><li></li></ul><p>401k with up to 4% match</p>\n",
      "</div></div><p><b>Benefits of Full Time Employment with Equiscript:</b></p>\n",
      "<div><ul><li>Competitive salaries</li></ul>\n",
      "<ul><li>Interesting, challenging, meaningful work</li></ul>\n",
      "<ul><li>Bright, high quality teammates</li></ul>\n",
      "<ul><li>Strong company culture based on teamwork and healthy competition</li></ul>\n",
      "<ul><li>Group health, dental, vision, life and disability insurance</li></ul>\n",
      "<ul><li>401K with up to a 4% match</li></ul>\n",
      "<ul><li>Wellness programs</li></ul>\n",
      "<ul><li>Company-provided training for personal and professional development</li></ul>\n",
      "<ul><li>Generous PTO Policy</li></ul>\n",
      "<ul><li>10 paid holidays annually</li></ul>\n",
      "<ul><li>Flexible schedule</li></ul>\n",
      "<ul><li>Casual dress code</li></ul>\n",
      "<ul><li>Parking</li></ul></div></div></div> \n",
      "\n",
      "************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Write a FOR loop that prints out the text from the first four rows of our DataFrame. \n",
    "# Make a separator between each full text entry - try \"print('\\n','*'*72)\" to see what this does. \n",
    "\n",
    "for iterator in range(0, 4):\n",
    "    print(df.loc[iterator, 'text'], '\\n')\n",
    "    print('*'*72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:45.383171Z",
     "start_time": "2020-06-14T15:27:45.377011Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Write a function using the .replace() command that cleans the text. \n",
    "# Hint: It may take several lines of code.\n",
    "\n",
    "def text_cleaner(text):\n",
    "    text = str(text)\n",
    "    text = text.replace('<div class=\"jobsearch-jobDescriptionText\" id=\"jobDescriptionText\">', '')\n",
    "    text = text.replace('<b>', '')\n",
    "    text = text.replace('</b>', '')\n",
    "    text = text.replace('<br/>', '')\n",
    "    text = text.replace('<div>', '')\n",
    "    text = text.replace('</div>', '')\n",
    "    text = text.replace('<li>', ' - ')\n",
    "    text = text.replace('</li>', '')\n",
    "    text = text.replace('<ul>', '')\n",
    "    text = text.replace('</ul>', '')\n",
    "    text = text.replace('</p>', '')\n",
    "    text = text.replace('<p>', '')\n",
    "    text = text.replace('\\n', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:46.236625Z",
     "start_time": "2020-06-14T15:27:46.231142Z"
    },
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About Pinterest:Millions of people across the world come to Pinterest to find new ideas every day. It’s where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. As a Pinterest employee, you’ll be challenged to take on work that upholds this mission and pushes Pinterest forward. You’ll grow as a person and a leader in your field, all the while helping users make their lives better in the positive corner of the internet.Before scaling their spend, advertisers want to know that Pinterest is performing for them. Come lead the team that interfaces with advertisers, collecting their sales data and matching it to our internal user databases, and build models and systems to connect the dots between the aspirations of pinners and the products offered by our partners.What you’ll do - Build and improve the machine learning models for ads measurement. - Develop models for user matching and conversion attributions. - Develop new techniques to mine the offsite signals to drive ads performance, e.g., retargeting. - Work on large scale data systems, backend services, and product integrationWhat we’re looking for: - MS or Ph.D degree in Computer Science, Statistics, or related field - 6+ years of relevant experience - Strong industry experience in machine learning - Cross-functional collaborator and strong communicator - Preferred, but not required, background in computational advertising#LI-JY1 \n",
      "\n",
      " ************************************************************************ \n",
      "\n",
      "\n",
      " - MS or PhD degree in computer science, operations research, statistics, engineering, or mathematics - 5+ years of experience in the field with a proven track record - Experience with fast prototyping - Experience with data mining or machine learning applications - Experience working effectively with software engineering teams - Excellent written and verbal communication skillsAmazon AI is looking for world class scientists to join its AI Lab. This group is entrusted with developing core machine learning algorithms for AWS. As a part of the AI Lab you will invent, implement, and deploy state of the art machine learning algorithms and systems. You will build prototypes and explore novel solutions to new problems at scale. You will interact closely with our customers and with the academic community. You will be at the heart of a growing and exciting focus area for AWS and work with other acclaimed engineers and world famous scientists.As a Scientist in the AI Lab are expected be an expert in an area relevant for large scale machine learning and its applications. Our particular focuses include temporal models particularly for forecasting, recommendation systems and reinforcement learning. Experience with deploying ML in practice is a plus.Your position will require you to:· Be an active member of a software development team.· Improve and accelerate our technology with science, statistical modeling, algorithm design, and prototyping.· Maintain an understanding of industry and technology trends in said area of research.· Contribute to Amazon's Intellectual Property through patents and/or external publications.· Understand business context to decisions made within and across groups.· Effectively communicate with senior management, colleagues, the open source community, and academia.· Recognize and help hire top talent in your field.· Mentor others in achieving their career growth potential.· Drive an independent research agenda that is well-aligned with business needs.Amazon.com is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation. \n",
      "\n",
      " ************************************************************************ \n",
      "\n",
      "\n",
      " - PhD or equivalent Master's Degree plus 4+ years of experience in a quantitative field. - Strong analytical skills. - 2+ years of experience of building predictive models for business and proficiency in model development and model validation. - Experience in efficiently handling large data sets, e.g., by using SQL, and databases in a business environment. - Experience with R, Python, Matlab or other scripting languages.The Amazon Devices-Demand Planning team is seeking an outstanding scientist with strong analytical and communication skills to help with demand forecasting and supply optimization for the entire Amazon device family of products and accessories. We develop scalable and robust state-of-the-art solutions that involve learning from different data sources. This role is central to the continued growth of Amazon Device division as we have grown from the first Kindle E-Reader to a vast portfolio of Echo, Fire TV, Fire Tablet, E-Reader, Ring and many other devices. With better forecasts we drive down supply chain costs, enabling the offer of lower prices and better in-stock selection for our customers.In this role, you will have an opportunity to both develop advanced scientific solutions and drive critical customer and business impacts. You will play a key role to drive end-to-end solutions from understanding our business requirements, exploring a large amount of historical data, building prototypes and exploring conceptually new solutions, to working with partner teams for prod deployment. You will collaborate closely with engineering peers as well as business stakeholders. You will be at the heart of a growing and exciting focus area for Amazon Devices.You are an individual with outstanding analytical abilities, excellent communication skills, and are comfortable working with cross-functional teams and systems. You will be responsible for researching, prototyping, experimenting, and analyzing predictive models.Key responsibilities: - Research and develop new methodologies for demand forecasting and price modeling. - Improve upon existing methodologies by adding new data sources and implementing model enhancements. - Drive scalable solutions. - Create and track accuracy and performance metrics (both technical and business metrics). - Create, enhance, and maintain technical documentation, and present to other scientists, engineers and business leaders. - Drive best practices on the team; mentor and guide junior members to achieve their career growth potential. - Experience with time series modeling and machine learning forecasting. - Experience with price modeling. \n",
      "\n",
      " ************************************************************************ \n",
      "\n",
      "\n",
      "At Equiscript, we improve access to healthcare in the communities we serve. We are able to do this through the motivation, ingenuity, and dedication of our talented team.Are you looking for a career where you can be part of a successful, growing business that is doing meaningful work in communities across the country?Located in historic North Charleston and Salt Lake City, Equiscript has been on the Inc. 5000 list of Fastest Growing Companies in the United States for the past four years and was chosen as one of the Best Places to Work in South Carolina three years in a row. We were also named one of Modern Healthcare's 2019 Best Places to Work in Healthcare and received the UT Healthy Worksite Award for 2020. We are a dynamic, growing company that values its employees and the patients and health centers we serve. As passionate people who enjoy coming to work and being part of a team, we are looking for candidates who will support and embrace our company’s Cause and Core Values. If this is you, apply today!Sr Director of Data &amp; Analytics::General Description:Equiscript is seeking an experienced candidate to serve in the role of Senior Director of Data and Analytics (SDDA). The SDDA will serve as a department and business leader, reporting to the CFO.High-Level Vision - :the SDDR is responsible for the big picture of the data priorities and strategy for the company. A high level of understanding of both data and strategy and the company’s business is required.Implementation -: The SDDR is responsible for the implementation of data-driven solutions within the company’s strategy at every level in the company. This requires the ability to manage teams on technical projects and build a business case around technical projects with many variables and uncertainty.Data Accuracy, Security, and Privacy - :the SDDR is responsible for collecting and maintaining accurate data, ensuring data security, and devising and implementing data privacy policies. The SDDR is to work with leadership to develop, define, and implement legal and ethical guidelines for the collection and use of data.Identifying Business Opportunities - :The SDDR is the person most responsible for identifying business opportunities discovered through data. In broad terms, the SDDR should increase revenue or decrease costs based upon information learned through data initiatives.Data-Driven Culture Leader - :The SDDR must serve as the leader for a data-driven culture within the company. This includes communicating to everyone at the company the importance of data, security, and privacy as well as the business value of data.Key Responsibilities:The SDDA will develop new ways to interpret and use data to advance Equiscript’s business. Working closely with the Sr. Director of Information Services, this position will build the structure and processes necessary to serve internal business users. In this role, the SDDA will define how Equiscript looks at reporting, tracking, and decision-making. The SDDA will: - Have expertise in creating and driving business value and growth through the effective use of data. - Collaborate with IT on the architecture, design, integration, and staging of data and the development, implementation, and maintenance of the associated data storage systems. - Be responsible for developing and administering Equiscript’s data and information strategy in order to facilitate and enhance organizational decision-making and data utilization across the company. - Lead a centralized Data and Analytics service and develop data-related policies and procedures; design, improve, and streamline organizational data systems; and drive innovation in the area of enterprise-wide data science, analysis, and visualization. - Be responsible for recruiting staff or engaging contractors that can use emerging technologies to improve the performance of the company. - Be responsible for developing and administering Equiscript’s data and information strategy in order to facilitate and enhance organizational decision-making and data utilization across the company. - Be responsible for overseeing the development and management of new machine learning and predictive modeling algorithms. - Be responsible for communicating effectively with all company departments and helping those departments perform to a higher standard with tools developed under the oversight of the SDDA. - Serve as a system-wide leader for data and analytics. Working closely with our client, patient, and pharmacy facing teams, develop a comprehensive understanding of the company’s overall business goals and data analytics needs - Analyze data, identify trends, and recommend how to improve and grow the business - Build and establish the automation of reports &amp; dashboards – identify and select analytics partners to improve reporting - Own and expand patient identification and patient lifecycle and lifetime value reporting - Present data in a clear and concise way to the executive team - Research the latest technologies and assess their impact on business trendsProfessional Qualities: - Evidence of strong leadership and communication skills at a C- or board level - Experience in information management projects and programs - Familiarity with big data solutions - Familiarity with data governance and quality control - Background in statistics or mathematics - Experience with creating best practices and methodologies for technical projects - Experience managing technical teams - Understanding of and experience building business cases for large technical projects - Familiarity with data modelling and visualization techniques - Strong business experience in the fieldPreferred Experience: - Bachelor’s or graduate degree in a quantitative field such as Mathematics, Statistics, Computer Science, Finance, Economics, or a related field. - 5-8 years of experience working with data analytics teams to provide reporting, analysis, modeling, and strategic insight - Experience with a variety of analytics platforms and database programming languages (i.e. CRM, Web Analytics, BI tools, etc) - Experience in integrating complex, inter-departmental processes and information strategies, and/or designing strategic metrics and scorecards required. - Experience running data analytics teams using the latest data mining, machine learning and/or artificial intelligence techniques required. Clinical background, or technical background in the healthcare domain is highly desirable. - Hands-on experience with implementing data management programs preferred. - Ability to provide written and oral interpretation of highly specialized terms and data, and the ability to present this data to others with different levels of expertiseComputer Skills: - Statistical analysis software/packages such as R, Minitab, SAS/STAT, etc. - Visualization/BI tools such as Tableau, PowerBI, etc. - Ability to write and tune SQL queries - Advanced Database/warehouse/lake knowledge; Master Data Management (MDM) applications; and Extract-Transform-Load (ETL/ELT) toolPhysical Requirements: - Requires the ability to sit or stand for long periods of time, occasional stooping, and reaching; May require lifting up to 25 pounds; requires a normal range of vision and hearing with or without accommodations.Additional Information: - Cleared Background Check RequiredEmployment Information: - Position located in North Charleston, SC but remote candidates will be considered. Remote candidates will be expected to travel approximately 20% to the main office. - Benefits include health plan, dental, vision, paid time off - Flex time - 401k with up to 4% matchBenefits of Full Time Employment with Equiscript: - Competitive salaries - Interesting, challenging, meaningful work - Bright, high quality teammates - Strong company culture based on teamwork and healthy competition - Group health, dental, vision, life and disability insurance - 401K with up to a 4% match - Wellness programs - Company-provided training for personal and professional development - Generous PTO Policy - 10 paid holidays annually - Flexible schedule - Casual dress code - Parking \n",
      "\n",
      " ************************************************************************ \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write a FOR loop that cleans and prints out the text from the first four rows of our DataFrame.\n",
    "# Place a separator between the text. \n",
    "\n",
    "\n",
    "for iterator in range(0, 4):\n",
    "    print(text_cleaner(df.loc[iterator, 'text']), '\\n\\n', '*'*72, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, write a loop that \n",
    ">1. pulls the raw text from each row in the DataFrame,\n",
    ">1. cleans the raw text,\n",
    ">1. places the clean text in a column called 'clean_text' in the appropriate row for each text, and\n",
    ">1. print out a sample of five entries from the DataFrame to verify our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:47.751347Z",
     "start_time": "2020-06-14T15:27:47.701042Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>pull_date</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>token_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>jl_900d5e7e57d3225e</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amazon.com Services LLC</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=900d5e7e57d3...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>- PhD or equivalent Master's Degree plus 4+ y...</td>\n",
       "      <td>['-', 'PhD', 'or', 'equivalent', 'Master', \"'s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>jl_7c6a63fde82c3b1e</td>\n",
       "      <td>Engineering Manager, Ads Machine Learning</td>\n",
       "      <td>Pinterest</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=7c6a63fde82c...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>About Pinterest:Millions of people across the ...</td>\n",
       "      <td>['About', 'Pinterest', ':', 'Millions', 'of', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>jl_b0fe1a91ffb0e24d</td>\n",
       "      <td>Applied Scientist</td>\n",
       "      <td>Amazon.com Services LLC</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=b0fe1a91ffb0...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>- MS or PhD degree in computer science, opera...</td>\n",
       "      <td>['-', 'MS', 'or', 'PhD', 'degree', 'in', 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>jl_d7e9536e93554823</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>new</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=d7e9536e9355...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>Puget Sound Energy is looking to grow our comm...</td>\n",
       "      <td>['Puget', 'Sound', 'Energy', 'is', 'looking', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>jl_f2da0761db3417ea</td>\n",
       "      <td>Senior Statistical Programmer</td>\n",
       "      <td>Seattle Genetics, Inc.</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=f2da0761db34...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>Summary:Seattle Genetics is seeking a Sr. Stat...</td>\n",
       "      <td>['Summary', ':', 'Seattle', 'Genetics', 'is', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 job_id                                      title  \\\n",
       "30  jl_900d5e7e57d3225e                             Data Scientist   \n",
       "43  jl_7c6a63fde82c3b1e  Engineering Manager, Ads Machine Learning   \n",
       "29  jl_b0fe1a91ffb0e24d                          Applied Scientist   \n",
       "57  jl_d7e9536e93554823                        Senior Data Analyst   \n",
       "96  jl_f2da0761db3417ea              Senior Statistical Programmer   \n",
       "\n",
       "                    company  \\\n",
       "30  Amazon.com Services LLC   \n",
       "43                Pinterest   \n",
       "29  Amazon.com Services LLC   \n",
       "57                      new   \n",
       "96   Seattle Genetics, Inc.   \n",
       "\n",
       "                                                  url  \\\n",
       "30  https://www.indeed.com/viewjob?jk=900d5e7e57d3...   \n",
       "43  https://www.indeed.com/viewjob?jk=7c6a63fde82c...   \n",
       "29  https://www.indeed.com/viewjob?jk=b0fe1a91ffb0...   \n",
       "57  https://www.indeed.com/viewjob?jk=d7e9536e9355...   \n",
       "96  https://www.indeed.com/viewjob?jk=f2da0761db34...   \n",
       "\n",
       "                                                 text   pull_date  \\\n",
       "30  <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-05-26   \n",
       "43  <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-05-31   \n",
       "29  <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-05-26   \n",
       "57  <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-05-31   \n",
       "96  <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-06-08   \n",
       "\n",
       "                                           clean_text  \\\n",
       "30   - PhD or equivalent Master's Degree plus 4+ y...   \n",
       "43  About Pinterest:Millions of people across the ...   \n",
       "29   - MS or PhD degree in computer science, opera...   \n",
       "57  Puget Sound Energy is looking to grow our comm...   \n",
       "96  Summary:Seattle Genetics is seeking a Sr. Stat...   \n",
       "\n",
       "                                           token_text  \n",
       "30  ['-', 'PhD', 'or', 'equivalent', 'Master', \"'s...  \n",
       "43  ['About', 'Pinterest', ':', 'Millions', 'of', ...  \n",
       "29  ['-', 'MS', 'or', 'PhD', 'degree', 'in', 'comp...  \n",
       "57  ['Puget', 'Sound', 'Energy', 'is', 'looking', ...  \n",
       "96  ['Summary', ':', 'Seattle', 'Genetics', 'is', ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, text in enumerate(df['text']):\n",
    "    df.loc[index, 'clean_text'] = text_cleaner(text)\n",
    "    \n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:48.604629Z",
     "start_time": "2020-06-14T15:27:48.600724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Senior Data ScientistAttunely is looking for a Senior Data Scientist to join our highly experienced team! This role will work with our Data Science group to develop individualized ML models for our customers in the financial sector. The ideal candidate is adept at developing and improving predictive models, as well as rigorously evaluating their effectiveness. They must have significant experience at working with large amounts of data from multiple sources and at translating their insights into functioning code. They must be comfortable working across teams and with a range of stakeholders. The right candidate will have a passion for economic modeling and for working with stakeholders to improve business outcomes, as well a drive for personal growth within the data science field.Responsibilities: - Work with the Data Science team to develop machine learning models for customers. - Use analytical methods to assess and improve models. - Researching new features and data sources for model improvement. - Work with the sales team to present analysis of model performance to customers. - Make improvements to the model creation pipeline (Python &amp; Spark). - Assist in cleaning and structuring data.Qualifications: - Experience with creating machine learning models for use in an economics context. - Excellent written and verbal communication skills for coordinating across teams. - Significant experience extracting insights from large data sets. - Experience testing hypotheses or models for accuracy against new data sets. - Experience using computer languages to manipulate and process data. - Significant data science experience, ideally including an advanced degree in a data-heavy quantitative field. - Experience with Python. - Experience with Apache Spark is a plus.Why Attunely:Attunely is a cloud-based, yield optimization platform for the delinquency stage in the credit ecosystem. We use machine learning to increase revenue recovery, thus improving outcomes for creditors, lowering risk in the credit ecosystem and facilitating a better consumer experience.We are a fun start-up crew based in the heart of original Seattle, Pioneer Square. We are a proud blend of techies, industry veterans, and newbies – our diverse experience makes us better. Benefits include fully-covered medical/dental/vision for every employee, a 401(k) plan, and unlimited PTO.Working at a start-up has many benefits, one of them is the potential to make it big. We see a unique and large addressable market opportunity with a higher probability of a rewarding and enduring career trajectory. As a true start-up, there is ample opportunity to have direct impact on product decisions, participate in learning and professional development opportunities, and take on legit leadership roles. If you like digging in and getting creative in a genuinely supportive environment, Attunely is the place for you!<i>At Attunely, we value diversity and treat all employees and job applicants based on merit, qualifications, competence, and talent. We are an equal opportunity employer and do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability, or other status protected by local, state, or federal law.</i>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[84, 'clean_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing Words \n",
    "\n",
    "\"Tokenizing\" is the splitting of a text entry into smaller parts, which we call 'tokens'. Tokens can be individual words, individual sentences, or individual paragraphs depending upon what unit of measure you want to use. For our purposes right now, we want to tokenize our clean_text by words and store these tokens (which will be a list) in our DataFrame. We are doing this so that later when we conduct an EDA, we will have the data ready for the EDA. Much of text analysis rests upon looking at each word individually (at our level for this discussion). There are techniques that look at the placement of the word in a sentence and the words surrounding each word, but that takes us into the world of neural networks, which is beyond our scope at the moment. \n",
    "\n",
    "There are several techniques to splitting up a string into words. We will look at two methods. \n",
    "\n",
    "### Method 1: The .split( ) Command\n",
    "\n",
    "The `.split()` command is not specific to tokenizing words, but we can use it to split a string into words. The `.split()` command can be used to split a string almost anyway that you want it to split; how it splits a string depends upon how you want it to split. \n",
    "\n",
    "The syntax of the `.split()` command is simple:\n",
    "> text = text.split('what spaces, letters or character by which you want the string split')\n",
    "\n",
    "In the function below, notice this syntax in line 3. \n",
    "\n",
    "But what are we doing in line 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:49.939025Z",
     "start_time": "2020-06-14T15:27:49.935143Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to using the split command to tokenize a string by words. \n",
    "\n",
    "def tokenize_by_words2(text):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.split(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Using nltk to Tokenize by Words\n",
    "\n",
    "The second method to tokenize a string by words is to use the nltk library's `word_tokenize()` function. \n",
    "\n",
    "\"NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, and wrappers for industrial-strength NLP libraries.\" [https://www.nltk.org/]\n",
    "\n",
    "In the next function, you will note that\n",
    ">1. in line 4, I added an `import` statement import the needed function out of the nltk library\n",
    ">1. in lines 5 & 6, I added the `str()` command to the tokenized text so that it saves as a tokenized string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:51.259744Z",
     "start_time": "2020-06-14T15:27:51.256690Z"
    }
   },
   "outputs": [],
   "source": [
    "#Tokenize a document's text given as a string to the word level and returning a list of tokenized words\n",
    "\n",
    "def tokenize_by_words(text):\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    token_text = str(word_tokenize(text))\n",
    "    return str(token_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:53.548506Z",
     "start_time": "2020-06-14T15:27:51.918489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>pull_date</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>token_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>jl_6373638f62ba4dc9</td>\n",
       "      <td>Data Scientist - WW Operations HR</td>\n",
       "      <td>Amazon.com Services LLC</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=6373638f62ba...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>- PhD in Statistics, Economics or closely rel...</td>\n",
       "      <td>['-', 'PhD', 'in', 'Statistics', ',', 'Economi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>jl_6373638f62ba4dc9</td>\n",
       "      <td>Data Scientist - WW Operations HR</td>\n",
       "      <td>new</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=6373638f62ba...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>- PhD in Statistics, Economics or closely rel...</td>\n",
       "      <td>['-', 'PhD', 'in', 'Statistics', ',', 'Economi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>jl_6373638f62ba4dc9</td>\n",
       "      <td>Data Scientist - WW Operations HR</td>\n",
       "      <td>Amazon.com Services LLC</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=6373638f62ba...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>- PhD in Statistics, Economics or closely rel...</td>\n",
       "      <td>['-', 'PhD', 'in', 'Statistics', ',', 'Economi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>jl_7aacd0672f017dcf</td>\n",
       "      <td>Applied Scientist - Delivery Experience - Mach...</td>\n",
       "      <td>Amazon.com Services LLC</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=7aacd0672f01...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>- Ph.D. in Computer Science, Statistics, Math...</td>\n",
       "      <td>['-', 'Ph.D.', 'in', 'Computer', 'Science', ',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>jl_7aacd0672f017dcf</td>\n",
       "      <td>Applied Scientist - Delivery Experience - Mach...</td>\n",
       "      <td>Amazon.com Services LLC</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=7aacd0672f01...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>- Ph.D. in Computer Science, Statistics, Math...</td>\n",
       "      <td>['-', 'Ph.D.', 'in', 'Computer', 'Science', ',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>jl_3fef1aac32437404</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>new</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=3fef1aac3243...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>At Indigo Slate, we are looking to build an on...</td>\n",
       "      <td>['At', 'Indigo', 'Slate', ',', 'we', 'are', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>jl_a03acf446a8a2c6b</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Amazon.com Services LLC</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=a03acf446a8a...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>Bachelor or Master's degree in Statistics, App...</td>\n",
       "      <td>['Bachelor', 'or', 'Master', \"'s\", 'degree', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>jl_b4de9892b2316f79</td>\n",
       "      <td>Lead Data Scientist - Deep Learning</td>\n",
       "      <td>The Climate Corporation</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=b4de9892b231...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Position OverviewThe Climate Corporation is lo...</td>\n",
       "      <td>['Position', 'OverviewThe', 'Climate', 'Corpor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>jl_65eb74587bb01b4f</td>\n",
       "      <td>Scientist - Data Analytics</td>\n",
       "      <td>Integral Consulting Inc.</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=65eb74587bb0...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>Integral Consulting Inc. (www.integral-corp.co...</td>\n",
       "      <td>['Integral', 'Consulting', 'Inc.', '(', 'www.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>jl_17d280b27ec3edf7</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Puget Sound Energy</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=17d280b27ec3...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>Puget Sound Energy is looking to grow our comm...</td>\n",
       "      <td>['Puget', 'Sound', 'Energy', 'is', 'looking', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  job_id                                              title  \\\n",
       "77   jl_6373638f62ba4dc9                  Data Scientist - WW Operations HR   \n",
       "60   jl_6373638f62ba4dc9                  Data Scientist - WW Operations HR   \n",
       "45   jl_6373638f62ba4dc9                  Data Scientist - WW Operations HR   \n",
       "79   jl_7aacd0672f017dcf  Applied Scientist - Delivery Experience - Mach...   \n",
       "46   jl_7aacd0672f017dcf  Applied Scientist - Delivery Experience - Mach...   \n",
       "66   jl_3fef1aac32437404                                     Data Scientist   \n",
       "26   jl_a03acf446a8a2c6b                              Senior Data Scientist   \n",
       "73   jl_b4de9892b2316f79                Lead Data Scientist - Deep Learning   \n",
       "89   jl_65eb74587bb01b4f                         Scientist - Data Analytics   \n",
       "100  jl_17d280b27ec3edf7                           Associate Data Scientist   \n",
       "\n",
       "                      company  \\\n",
       "77    Amazon.com Services LLC   \n",
       "60                        new   \n",
       "45    Amazon.com Services LLC   \n",
       "79    Amazon.com Services LLC   \n",
       "46    Amazon.com Services LLC   \n",
       "66                        new   \n",
       "26    Amazon.com Services LLC   \n",
       "73    The Climate Corporation   \n",
       "89   Integral Consulting Inc.   \n",
       "100        Puget Sound Energy   \n",
       "\n",
       "                                                   url  \\\n",
       "77   https://www.indeed.com/viewjob?jk=6373638f62ba...   \n",
       "60   https://www.indeed.com/viewjob?jk=6373638f62ba...   \n",
       "45   https://www.indeed.com/viewjob?jk=6373638f62ba...   \n",
       "79   https://www.indeed.com/viewjob?jk=7aacd0672f01...   \n",
       "46   https://www.indeed.com/viewjob?jk=7aacd0672f01...   \n",
       "66   https://www.indeed.com/viewjob?jk=3fef1aac3243...   \n",
       "26   https://www.indeed.com/viewjob?jk=a03acf446a8a...   \n",
       "73   https://www.indeed.com/viewjob?jk=b4de9892b231...   \n",
       "89   https://www.indeed.com/viewjob?jk=65eb74587bb0...   \n",
       "100  https://www.indeed.com/viewjob?jk=17d280b27ec3...   \n",
       "\n",
       "                                                  text   pull_date  \\\n",
       "77   <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-06-01   \n",
       "60   <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-05-31   \n",
       "45   <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-05-31   \n",
       "79   <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-06-01   \n",
       "46   <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-05-31   \n",
       "66   <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-05-31   \n",
       "26   <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-05-25   \n",
       "73   <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-06-01   \n",
       "89   <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-06-08   \n",
       "100  <div class=\"jobsearch-jobDescriptionText\" id=\"...  2020-06-08   \n",
       "\n",
       "                                            clean_text  \\\n",
       "77    - PhD in Statistics, Economics or closely rel...   \n",
       "60    - PhD in Statistics, Economics or closely rel...   \n",
       "45    - PhD in Statistics, Economics or closely rel...   \n",
       "79    - Ph.D. in Computer Science, Statistics, Math...   \n",
       "46    - Ph.D. in Computer Science, Statistics, Math...   \n",
       "66   At Indigo Slate, we are looking to build an on...   \n",
       "26   Bachelor or Master's degree in Statistics, App...   \n",
       "73   Position OverviewThe Climate Corporation is lo...   \n",
       "89   Integral Consulting Inc. (www.integral-corp.co...   \n",
       "100  Puget Sound Energy is looking to grow our comm...   \n",
       "\n",
       "                                            token_text  \n",
       "77   ['-', 'PhD', 'in', 'Statistics', ',', 'Economi...  \n",
       "60   ['-', 'PhD', 'in', 'Statistics', ',', 'Economi...  \n",
       "45   ['-', 'PhD', 'in', 'Statistics', ',', 'Economi...  \n",
       "79   ['-', 'Ph.D.', 'in', 'Computer', 'Science', ',...  \n",
       "46   ['-', 'Ph.D.', 'in', 'Computer', 'Science', ',...  \n",
       "66   ['At', 'Indigo', 'Slate', ',', 'we', 'are', 'l...  \n",
       "26   ['Bachelor', 'or', 'Master', \"'s\", 'degree', '...  \n",
       "73   ['Position', 'OverviewThe', 'Climate', 'Corpor...  \n",
       "89   ['Integral', 'Consulting', 'Inc.', '(', 'www.i...  \n",
       "100  ['Puget', 'Sound', 'Energy', 'is', 'looking', ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for index, text in enumerate(df['clean_text']):\n",
    "    df.loc[index, 'token_text'] = tokenize_by_words(text)\n",
    "    \n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning White Space\n",
    "\n",
    "White space is sometimes a help, but mostly it is just chatter that we need to get rid of in order to have clean data. In this part of the notebook, we will discuss techniques for cleaning white space out of a document and from our tokens, and then we will store that text in our DataFrame, again so that we have clean data readily available for our EDA in the next notebook. \n",
    "\n",
    "### Clean Leading and Trailing White Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:53.554105Z",
     "start_time": "2020-06-14T15:27:53.550336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The   Red fox   Jumped  over The  Lazy dog. '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = ' The   Red fox   Jumped  over The  Lazy dog. '\n",
    "\n",
    "test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:54.305111Z",
     "start_time": "2020-06-14T15:27:54.301371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The   Red fox   Jumped  over The  Lazy dog.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = test_string.strip()\n",
    "    \n",
    "phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean White Space using .replace( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:56.314435Z",
     "start_time": "2020-06-14T15:27:56.310175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Red fox Jumped over The Lazy dog.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = test_string.replace('   ', ' ')\n",
    "test_string = test_string.replace('  ', ' ')\n",
    "test_string.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Text\n",
    "\n",
    "Normalizing Text meerly means that we are going to make the text the same. For a human, a capitalized word and its lower case version are still the same word. To Python, they are different words. By normalizing the text, we are making every word one case so that have clean text that Python can analyze. \n",
    "\n",
    "### Make all words lower case using .lower( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:57.698251Z",
     "start_time": "2020-06-14T15:27:57.694293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the red fox jumped over the lazy dog. '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make all words upper case using .upper( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:27:59.260836Z",
     "start_time": "2020-06-14T15:27:59.256851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' THE RED FOX JUMPED OVER THE LAZY DOG. '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the First Letter in Each Word Uppercase using .title( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:28:00.393705Z",
     "start_time": "2020-06-14T15:28:00.390216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The Red Fox Jumped Over The Lazy Dog. '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "As you look at the output from the line above, you see that we have spaces and at the end of the line. Each word in the string is capitalized. We want to correct these two issues. \n",
    "\n",
    "In the next block, using what you have learned in all of our lessons, write a function that would take any string and return a string that is correct with capitalization and non-capitalized words.\n",
    "\n",
    "After writing the function, run the function on the list of strings in the second block. Did you get it correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:28:02.289638Z",
     "start_time": "2020-06-14T15:28:02.285706Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write a function to correct the text capitalization\n",
    "# The function should capitalize the first letter only in each string.\n",
    "\n",
    "def correct_captialization(text):\n",
    "    new_string = []#So we have a holder\n",
    "    for string in text:#The text is a list of strings in our example\n",
    "        string = string.lower()#make it all lower case\n",
    "        new_string.append(string[0].upper()+string[1:])#Now make only the first letter upper case\n",
    "    return new_string #Return the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:28:02.942768Z",
     "start_time": "2020-06-14T15:28:02.939439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The large box contained her gift.', 'Jack does not like getting water.']\n"
     ]
    }
   ],
   "source": [
    "# Use the following strings list to test your function\n",
    "\n",
    "strings_list = ['THE large Box cOntained Her gift.', 'Jack DoeS Not LiKe Getting Water.']\n",
    "\n",
    "print(correct_captialization(strings_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now save our DataFrame for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:28:08.162534Z",
     "start_time": "2020-06-14T15:28:08.100454Z"
    }
   },
   "outputs": [],
   "source": [
    "job_title = job_title.replace(' ', '_')\n",
    "df.to_csv('data/'+job_title+'_job_search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
